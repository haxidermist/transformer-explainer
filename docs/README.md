# Zen and the Art of LLM Inference

This is the GitHub Pages deployment for the ebook **"Zen and the Art of LLM Inference"**.

## ğŸ“– Read Online

The ebook is available at: **https://haxidermist.github.io/transformer-explainer/**

## ğŸ“¥ Download PDF

To create a PDF version:
1. Open the [online version](https://haxidermist.github.io/transformer-explainer/)
2. Press `Ctrl+P` (or `Cmd+P` on Mac)
3. Select "Save as PDF"
4. Ensure "Background graphics" is enabled for best results

## ğŸ“š What's Inside

An exploration of transformer architectures through the lens of the Transformer Explainer visualization tool, inspired by Robert M. Pirsig's "Zen and the Art of Motorcycle Maintenance."

### Chapters Available:
- **Chapter 1:** What Is a Transformer?
- **Chapter 2:** The Anatomy of GPT-2
- **Interlude I:** On Understanding
- **Chapter 8:** Mixture of Experts
- **Chapter 10:** Query or Completion?

### Features:
- Interactive SVG diagrams
- Mathematical equations (MathJax)
- Syntax-highlighted code examples
- Print-optimized for PDF export
- Professional typography and design

## ğŸ”§ Source Code

The Transformer Explainer visualization that inspired this book:
- **Repository:** https://github.com/haxidermist/transformer-explainer
- **Original:** https://github.com/poloclub/transformer-explainer
- **Live Demo:** http://localhost:5174 (when running locally)

## ğŸ“ Version

**v0.1.0** - January 2025

This ebook is designed to grow over time. Check back for new chapters and updates!

---

*"The real cycle you're working on is a cycle called yourself." â€” Robert M. Pirsig*
